# Generando streams desde una inferencia bÃ¡sica

Pedirle algo al LLM es crear/generar/detonar una inferencia. âœ…

```ts
import { streamText } from "ai";

const chat = (prompt: string) =>
  streamText({
    model,
    system,
    prompt,
  });
```

Creamos la funciÃ³n chat para poder recibir el prompt desde fuera. ğŸ¤“
Los streams son la manera mÃ¡s moderna y adoptada por la industria web para crear la mejor experiencia de chat con robots. ğŸ¤–

## Â¿CÃ³mo ejecutamos este script?

Vamos a ejecutar nuestro programa y recorrer el stream para devolver parte por parte a la consola.

```ts
const { textStream } = chat("DÃ­me un poema robÃ³tico");

for await (const part of textStream) {
  process.stdout.write(part);
}
```

Ejecutamos el programa con: `npm run dev` que a su vez hace, simplemente: `tsx index.ts`. `tsx` es la manera mÃ¡s fÃ¡cil de ejecutar TypeScript en Node.js. âœ…

## El entorno web

No siempre queremos ejecutar scripts desde nuestra terminal, a veces se apetece crearnos una interfaz web, para ello usaremos el framework para crear un servidor mÃ¡s famoso de Node.js: express.js. âœ… Todo esto, en el siguiente ejercicio. ğŸ§‘ğŸ»â€ğŸ’»

> ğŸ‘€ Hoy en dÃ­a es mÃ¡s recomendable usar Hono que es compatible con multiples runtimes no solo Node.js. AdemÃ¡s de ser mucho mÃ¡s rÃ¡pido y usar patterns mÃ¡s modernos y apegados a la programaciÃ³n funcional. ğŸ‘ğŸ¼ Hay una branch bonus en la que usamos un servidor Hono en vez de express. `origin/ejercicio/bonus-migrate_to_hono`. â¬…ï¸

Pero, si aÃºn te sientes principiante y quieres ir mÃ¡s despacio, siempre puedes quedarte con express y sentirte mÃ¡s cÃ³modo(a) mientras vas aprendiendo mÃ¡s. ğŸ˜¬
